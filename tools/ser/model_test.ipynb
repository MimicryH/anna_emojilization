{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0+cu101\n"
     ]
    }
   ],
   "source": [
    "from ser.feature_extract import extract_features_from\n",
    "from ser.Yoon_model import YoonBREAudio, YoonBREText\n",
    "import torch\n",
    "from torchtext import data\n",
    "import numpy as np\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "label_dict = {\n",
    "    \"neu\": 0,\n",
    "    \"ang\": 1,\n",
    "    \"sad\": 2,\n",
    "    'hap': 3\n",
    "}\n",
    "MAX_TEXT_LEN = 128\n",
    "\n",
    "vector_path = 'D:/DoobiePJ/2020Ali/SER_test/.vector_cache/'\n",
    "x_t = np.load('D:\\DoobiePJ/2020Ali\\demo\\ser/x_text.npy', allow_pickle=True)\n",
    "TEXT = data.Field()\n",
    "TEXT.build_vocab(x_t, max_size=25000, vectors='glove.6B.100d', vectors_cache=vector_path, unk_init=torch.Tensor.normal_)\n",
    "\n",
    "\n",
    "tknzr = TweetTokenizer()\n",
    "# Create a Tokenizer with the default settings for English\n",
    "# including punctuation rules and exceptions\n",
    "\n",
    "model_a = YoonBREAudio(num_class=4, mfcc_size=119, prosody_size=35, hidden_size=128, num_layers=2, dropout=0.3)\n",
    "model_a = torch.load('D:\\DoobiePJ/2020Ali\\demo\\ser/Yoon_audio.pth')\n",
    "model_t = YoonBREText(num_class=4, vocab_size=len(TEXT.vocab), embedding_dim=100,\n",
    "                      pad_idx=TEXT.vocab.stoi[TEXT.pad_token], hidden_size=128, num_layers=2, dropout=.3,\n",
    "                      bidirectional=True, use_cuda=True)\n",
    "model_t = torch.load('D:\\DoobiePJ/2020Ali\\demo\\ser/Yoon_text.pth')\n",
    "\n",
    "\n",
    "def ser(wav_file):\n",
    "    audio_feature = extract_features_from(wav_file)\n",
    "    print(audio_feature)\n",
    "    prediction_a = model_a(audio_feature)\n",
    "    return prediction_a\n",
    "\n",
    "\n",
    "def ter(text):\n",
    "    tokens = tknzr.tokenize(text)\n",
    "    if len(tokens) > MAX_TEXT_LEN:\n",
    "        tokens = tokens[:MAX_TEXT_LEN]\n",
    "    else:\n",
    "        tokens = tokens + [TEXT.pad_token] * (MAX_TEXT_LEN - len(tokens))\n",
    "    idxs = []\n",
    "    for token in tokens:\n",
    "        idxs.append(TEXT.vocab.stoi[str(token)])\n",
    "    t = torch.tensor(idxs).cuda()\n",
    "    t = t.view(1, t.shape[0])\n",
    "    prediction_a = model_t(t)[0]\n",
    "    for i, num in enumerate(label_dict):\n",
    "        print(\"%s: %f\" % (num, prediction_a[i]))\n",
    "    return prediction_a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neu: 0.000001\n",
      "ang: 0.000000\n",
      "sad: 0.000003\n",
      "hap: 0.999996\n",
      "tensor([5.6480e-07, 6.7609e-09, 3.1896e-06, 1.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "neu: 0.000000\n",
      "ang: 0.000002\n",
      "sad: 0.000003\n",
      "hap: 0.999995\n",
      "tensor([8.6951e-08, 2.0325e-06, 2.7256e-06, 1.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "neu: 0.000000\n",
      "ang: 0.999922\n",
      "sad: 0.000076\n",
      "hap: 0.000001\n",
      "tensor([1.3301e-07, 9.9992e-01, 7.6365e-05, 1.4830e-06], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "neu: 0.000000\n",
      "ang: 0.000000\n",
      "sad: 0.000000\n",
      "hap: 1.000000\n",
      "tensor([7.0751e-09, 4.2373e-09, 2.8449e-08, 1.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "neu: 0.951074\n",
      "ang: 0.000061\n",
      "sad: 0.002022\n",
      "hap: 0.046843\n",
      "tensor([9.5107e-01, 6.0861e-05, 2.0224e-03, 4.6843e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "neu: 0.000018\n",
      "ang: 0.994746\n",
      "sad: 0.000024\n",
      "hap: 0.005212\n",
      "tensor([1.8262e-05, 9.9475e-01, 2.4058e-05, 5.2120e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "neu: 0.000027\n",
      "ang: 0.000009\n",
      "sad: 0.000087\n",
      "hap: 0.999877\n",
      "tensor([2.6808e-05, 9.1907e-06, 8.7223e-05, 9.9988e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "neu: 0.000000\n",
      "ang: 0.000000\n",
      "sad: 0.000000\n",
      "hap: 1.000000\n",
      "tensor([1.3995e-07, 1.9140e-08, 2.8902e-07, 1.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "ang_text = [\n",
    "    \"What the hell?\",\n",
    "    \"I hate you!\",\n",
    "    \"I am angry. I'm like a large tornado of anger, swirling about.\",\n",
    "    \"Yes, General. I do. You're the man responsible for the deaths of two of my men. Now, open up those crates before I grab you by your hair plugs and bitch slap that smug look off of your face.\",\n",
    "]\n",
    "\n",
    "sad_text = [\n",
    "    \"I don't feel good. I think I'm crying.\",\n",
    "    \"I can't stand living without you for one second. I'm not happy about that.\",\n",
    "    \"I'm poor, Black, I might even be ugly, but dear god, I'm here. I'm here.\",\n",
    "    \"When you burst out crying alone and u realize that no one truly knows how unhappy you really are because you don't want anyone to know\"\n",
    "]\n",
    "\n",
    "happy_text = [\n",
    "    \"Today was perfect.\",\n",
    "    \"Can't believe that I got the first prize. What a luck!\",\n",
    "    \"one thing I can say is that you kept me smiling\",\n",
    "    \"I'm so excited to see Nat tonight And how happy and cheery she is! then I'm even more excited for her to get on social media\",\n",
    "    \"you know it's beauty when the smile is her best curve\",\n",
    "    \"I'm still laughing 'Bitch took my pillow' line.\",\n",
    "    \"Good morning. Let's start with a smile! Let's enjoy life in a cheerful way! Don't worry be happy!\",\n",
    "    \"Nothing lovelier than your great mate sending the most joyful and sweet pic.\"\n",
    "]\n",
    "\n",
    "# for sentence in ang_text:\n",
    "#     print(ter(sentence))\n",
    "#\n",
    "# for sentence in sad_text:\n",
    "#     print(ter(sentence))\n",
    "\n",
    "for sentence in happy_text:\n",
    "    print(ter(sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}